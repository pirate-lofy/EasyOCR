number: '٠١٢٣٤٥٦٧٨٩'
symbol: ""
lang_char: 'اأإآبتثجحخدذرزسشصضطظعغفقكلمنهوىيءئؤة'
experiment_name: 'ar_fake'
train_data: 'all_data'
valid_data: 'all_data/ar_val'
manualSeed: 1111
workers: 6
batch_size: 32 #32
num_iter: 30000
valInterval: 2000
saved_model: '' #'saved_models/en_filtered/iter_300000.pth'
FT: False
optim: False # default is Adadelta
lr: 1. # as in Adadelta paper
beta1: 0.9
rho: 0.95
eps: 0.00000001
grad_clip: 5
#Data processing
select_data: 'ar' # this is dataset folder in train_data
batch_ratio: '1'
total_data_usage_ratio: 1.0
batch_max_length: 34    # check for possible value
imgH: 32
imgW: 600
rgb: False
contrast_adjust: False # need to be changed in the future training
sensitive: True
PAD: True
contrast_adjust: 0.0 # need to be checked if enabled the adjustment
data_filtering_off: False
# Model Architecture
Transformation: 'None'
FeatureExtraction: 'ResNet'
SequenceModeling: 'LSTM'
Prediction: 'CTC'
num_fiducial: 20
input_channel: 1
output_channel: 256
hidden_size: 256
decode: 'greedy'
new_prediction: False
freeze_FeatureFxtraction: True # takecare
freeze_SequenceModeling: False
